import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import LabelEncoder

def run_machine_learning(df):
    st.title("ğŸ¤– EntraÃ®nement du ModÃ¨le de Classification")

    if df is None or df.empty:
        st.error("âŒ Aucune donnÃ©e disponible pour l'entraÃ®nement")
        return None
    
    st.header("ğŸ“‹ VÃ©rification des DonnÃ©es")
    col1, col2, col3 = st.columns(3)
    col1.metric("Lignes", df.shape[0])
    col2.metric("Colonnes", df.shape[1])
    col3.metric("DonnÃ©es manquantes", df.isnull().sum().sum())

    # -------------------------------
    # âœ… Target
    # -------------------------------
    st.header("ğŸ¯ Target")

    all_columns = df.columns.tolist()

    if 'target_encoded' in all_columns:
        target_col = 'target_encoded'
        st.success("âœ… Target utilisÃ©e : `target_encoded`")

        if 'label_mapping' in st.session_state:
            st.info("**Correspondance des classes :**")
            for text_label, numeric_value in st.session_state.label_mapping.items():
                st.write(f"â€¢ **{text_label}** â†’ Classe {numeric_value}")

    elif 'target' in all_columns:
        target_col = 'target'
        st.warning("âš ï¸ `target` dÃ©tectÃ©e â€” encodage en coursâ€¦")

        if df[target_col].dtype == 'object':
            le = LabelEncoder()
            df['target_encoded'] = le.fit_transform(df[target_col])
            target_col = 'target_encoded'
            st.session_state.label_mapping = dict(zip(le.classes_, le.transform(le.classes_)))
            st.success("âœ… Target encodÃ©e â†’ `target_encoded`")

            st.info("**Correspondance :**")
            for text_label, numeric_value in st.session_state.label_mapping.items():
                st.write(f"â€¢ **{text_label}** â†’ Classe {numeric_value}")
    else:
        st.error("âŒ Aucune target trouvÃ©e (`target` ou `target_encoded`)")
        return None

    st.text_input("Target sÃ©lectionnÃ©e :", target_col, disabled=True)

    # -------------------------------
    # Analyse de la target
    # -------------------------------
    st.header("ğŸ“Š Analyse de la Target")
    y = df[target_col]
    n_classes = len(np.unique(y))

    col1, col2 = st.columns(2)
    col1.metric("Nombre de classes", n_classes)
    col1.metric("Total Ã©chantillons", len(y))

    col2.write("**Distribution des classes :**")
    for cls, count in pd.Series(y).value_counts().sort_index().items():
        percentage = count / len(y) * 100
        label_text = ""
        if 'label_mapping' in st.session_state:
            label_text = [k for k, v in st.session_state.label_mapping.items() if v == cls][0]
        col2.write(f"â€¢ Classe {cls} ({label_text}) : {count} Ã©chantillons ({percentage:.1f}%)")

    # -------------------------------
    # DÃ©finition des features
    # -------------------------------
    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
    feature_cols = [c for c in numeric_cols if c not in ['target', 'target_encoded']]

    #st.info(f"âœ… **Variables utilisÃ©es automatiquement :** {feature_cols}")

    # -------------------------------
    # RÃ©cupÃ©ration du split depuis la prÃ©paration
    # -------------------------------
    if not all(k in st.session_state for k in ["X_train", "X_test", "y_train", "y_test"]):
        st.error("âŒ Veuillez d'abord prÃ©parer les donnÃ©es (split manquant)")
        return None

    X_train = st.session_state.X_train[feature_cols]
    X_test = st.session_state.X_test[feature_cols]
    y_train = st.session_state.y_train
    y_test = st.session_state.y_test

    # -------------------------------
    # âœ… Choix du modÃ¨le
    # -------------------------------
    st.header("ğŸ§  Configuration du ModÃ¨le")

    model_choice = st.radio("SÃ©lectionnez l'algorithme :", ["Random Forest", "RÃ©gression Logistique"], horizontal=True)

    if model_choice == "Random Forest":
        n_estimators = st.slider("Nombre d'arbres", 10, 200, 100)
        max_depth = st.slider("Profondeur max", 2, 30, 10)
        model = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, random_state=42)
    else:
        C = st.slider("RÃ©gularisation (C)", 0.01, 10.0, 1.0)
        max_iter = st.slider("ItÃ©rations max", 100, 2000, 500)
        model = LogisticRegression(C=C, max_iter=max_iter, random_state=42)

    # -------------------------------
    # âœ… EntraÃ®nement
    # -------------------------------
    st.header("ğŸš€ EntraÃ®nement du ModÃ¨le")

    if st.button("ğŸš€ Lancer l'EntraÃ®nement", type="primary"):

        model.fit(X_train, y_train)
        st.success("âœ… ModÃ¨le entraÃ®nÃ© !")

        # âœ… Importance des variables
        st.subheader("ğŸ“Œ Importance des Variables")

        importances = model.feature_importances_ if model_choice == "Random Forest" else np.abs(model.coef_[0])

        feat_imp = pd.DataFrame({"Variable": feature_cols, "Importance": importances}).sort_values(by="Importance", ascending=False)
        st.dataframe(feat_imp, width="stretch")

        # Graphique importance
        st.subheader("ğŸ“Š Importance des Variables")
        fig, ax = plt.subplots(figsize=(10, 5))
        sns.barplot(data=feat_imp, x="Importance", y="Variable", hue="Variable", palette="viridis", legend=False, ax=ax)
        ax.set_title(f"Importance des Variables - {model_choice}")
        st.pyplot(fig)

        # âœ… Tree example for RF
        if model_choice == "Random Forest":
            from sklearn import tree
            estimator = model.estimators_[0]
            fig, ax = plt.subplots(figsize=(25, 12))
            tree.plot_tree(estimator, feature_names=feature_cols, filled=True, rounded=True, fontsize=7)
            st.subheader("ğŸŒ³ PrÃ©sentation du Random Forest")
            st.pyplot(fig)

        # Stocker rÃ©sultats pour l'Ã©valuation
        results = {
            "X_test": X_test,
            "y_test": y_test,
            "feature_cols": feature_cols,
            "model_type": model_choice
        }

        return model, results
